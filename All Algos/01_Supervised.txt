# -----------------------------
# ğŸ“˜ Scikit-learn Supervised Algorithms â€“ With Use Cases
# -----------------------------

# 1ï¸âƒ£ Linear Models
# -------------------------------------------------------
# LinearRegression              â†’ Predict continuous values (e.g., house prices)
# Ridge / Lasso / ElasticNet   â†’ Use when regularization is needed
# LogisticRegression           â†’ Classify binary or multiclass problems (e.g., spam detection)
# SGDClassifier / SGDRegressor â†’ Large-scale problems, online learning (e.g., click prediction)

# 2ï¸âƒ£ Tree-Based Models
# -------------------------------------------------------
# DecisionTreeClassifier / Regressor      â†’ Easy to interpret; overfits easily
# RandomForestClassifier / Regressor      â†’ High accuracy, good default model (e.g., fraud detection)
# ExtraTreesClassifier / Regressor        â†’ Faster, more randomness
# GradientBoostingClassifier / Regressor  â†’ Top accuracy on tabular data (e.g., customer churn)
# HistGradientBoostingClassifier / Regressor â†’ Large datasets; fast training

# 3ï¸âƒ£ Support Vector Machines (SVM)
# -------------------------------------------------------
# SVC (Classifier)           â†’ Text/image classification (e.g., digit recognition)
# SVR (Regressor)            â†’ Predicting continuous outcomes (e.g., salary estimation)
# LinearSVC / LinearSVR      â†’ For large datasets with linear decision boundaries

# 4ï¸âƒ£ K-Nearest Neighbors (KNN)
# -------------------------------------------------------
# KNeighborsClassifier       â†’ Recommender systems, similarity-based classification
# KNeighborsRegressor        â†’ Predict numerical values from similar neighbors (e.g., rent estimate)

# 5ï¸âƒ£ Naive Bayes
# -------------------------------------------------------
# GaussianNB                 â†’ For continuous features (e.g., disease prediction)
# MultinomialNB              â†’ Text classification with word counts (e.g., news, spam)
# BernoulliNB                â†’ Binary features (e.g., sentiment classification)
# ComplementNB               â†’ Good for imbalanced text classification

# 6ï¸âƒ£ Discriminant Analysis
# -------------------------------------------------------
# LinearDiscriminantAnalysis (LDA)   â†’ Dimensionality reduction + classification (e.g., gene types)
# QuadraticDiscriminantAnalysis (QDA)â†’ Non-linear class boundaries (e.g., credit scoring)

# 7ï¸âƒ£ Ensemble Methods
# -------------------------------------------------------
# VotingClassifier           â†’ Combine multiple classifiers (e.g., ensemble voting)
# BaggingClassifier / Regressor â†’ Reduces overfitting in unstable models (e.g., trees)
# AdaBoostClassifier / Regressor  â†’ Focuses on mistakes; good on simple models (e.g., face detection)
# GradientBoostingClassifier / Regressor â†’ Great accuracy on tabular datasets
# StackingClassifier / Regressor â†’ Combines outputs of multiple models (e.g., for ML competitions)

# -----------------------------
# âœ… Summary Table â€“ When to Use What
# -----------------------------
# Linear Models       â†’ Fast, linearly-separable data, interpretable
# Tree Models         â†’ High accuracy, tabular data, feature importance
# SVM                 â†’ Small datasets, text/image classification
# KNN                 â†’ Simple problems, smaller datasets
# Naive Bayes         â†’ Text, count-based problems, probabilistic outputs
# Discriminant        â†’ Statistical classification + dimensionality reduction
# Ensembles           â†’ Complex datasets, best overall performance

# -----------------------------
# ğŸ§  Typical Use Cases by Industry
# -----------------------------
# Finance       â†’ Credit risk, loan default, fraud detection
# Healthcare    â†’ Disease diagnosis, medical cost prediction
# Marketing     â†’ Customer churn, segmentation
# Retail/Ecomm  â†’ Product recommendations, price prediction
# NLP/Text      â†’ Spam detection, sentiment analysis
# Vision        â†’ Face/digit recognition
